{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bmgpt/telegram-deep-fakes-bot/blob/master/new_of_deep_fake_telegram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdO_RxQZLahB"
      },
      "source": [
        "# Telegram deep fake bot\n",
        "\n",
        "[Github repo](https://github.com/albertoxamin/telegram-deep-fakes-bot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCDNKsEGLtR6"
      },
      "source": [
        "**Clone deep-fake repository**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCMFMJV7K-ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df79c73-dd3f-40fc-80b5-c2b2db8e43ac"
      },
      "source": [
        "!git clone https://github.com/AliaksandrSiarohin/first-order-model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'first-order-model'...\n",
            "remote: Enumerating objects: 393, done.\u001b[K\n",
            "remote: Counting objects: 100% (81/81), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 393 (delta 41), reused 66 (delta 38), pack-reused 312\u001b[K\n",
            "Receiving objects: 100% (393/393), 72.19 MiB | 19.50 MiB/s, done.\n",
            "Resolving deltas: 100% (204/204), done.\n",
            "Updating files: 100% (48/48), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBp6l_4bBYUL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e5d2267-77a3-4e99-b6e6-8bc82b56777f"
      },
      "source": [
        "cd first-order-model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/first-order-model/first-order-model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcMX7ueZO0Oa"
      },
      "source": [
        "**Mount your Google drive folder on Colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDbMA8R9OuUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81cc67c9-bc08-4ac8-b504-c318b88dc746"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsgVK1EURXkd"
      },
      "source": [
        "**Add folder https://drive.google.com/drive/folders/1kZ1gCnpfU0BnpdU47pLM_TQ6RypDDqgw?usp=sharing  to your google drive.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW-ipQXPOWUo"
      },
      "source": [
        "**Load the deep fake libraries**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ffmpeg"
      ],
      "metadata": {
        "id": "jC26WKt4Gv5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab9b7424-8df2-4953-fa61-4b9516c56c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ffmpeg in /usr/local/lib/python3.10/dist-packages (1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxi6-riLOgnm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "8c6152e1-159f-40e8-a6cb-bfc3febac20e"
      },
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from skimage.transform import resize\n",
        "from IPython.display import HTML\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from demo import load_checkpoints\n",
        "from demo import make_animation\n",
        "from skimage import img_as_ubyte\n",
        "cpu = False\n",
        "generator, kp_detector = load_checkpoints(config_path='config/vox-adv-256.yaml',\n",
        "                            checkpoint_path='/content/gdrive/My Drive/first-order-motion-model/vox-adv-cpk.pth.tar',cpu=cpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-24392219b583>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimg_as_ubyte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m generator, kp_detector = load_checkpoints(config_path='config/vox-adv-256.yaml',\n\u001b[0m\u001b[1;32m     14\u001b[0m                             checkpoint_path='/content/gdrive/My Drive/first-order-motion-model/vox-adv-cpk.pth.tar',cpu=cpu)\n",
            "\u001b[0;32m/content/first-order-model/demo.py\u001b[0m in \u001b[0;36mload_checkpoints\u001b[0;34m(config_path, checkpoint_path, cpu)\u001b[0m\n\u001b[1;32m     31\u001b[0m                                         **config['model_params']['common_params'])\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     kp_detector = KPDetector(**config['model_params']['kp_detector_params'],\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \"\"\"\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \"\"\"\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjM7ubVfWrwT"
      },
      "source": [
        "**Install the telegram bot framework**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFGm3aa8Nnq4"
      },
      "source": [
        "!pip install pyTelegramBotAPI"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMBUah6_p4q2"
      },
      "source": [
        "## Make it a telegram bot\n",
        "\n",
        "contact the [@BotFather](https://t.me/BotFather) on telegram and create a new bot with the command `/newbot`\n",
        "\n",
        "After you've given the bot a name and username you should receive a message that looks like this ![alt text](https://i.imgur.com/BT8hHEL.png)\n",
        "\n",
        "\n",
        "Now copy and the paste the token below in the `API_TOKEN`.\n",
        "\n",
        "Now you can run this cell and start chatting with the bot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMSzRMloD8Mr"
      },
      "source": [
        "import telebot\n",
        "import requests\n",
        "import shutil\n",
        "import subprocess\n",
        "import os.path\n",
        "\n",
        "API_TOKEN = '6503597856:AAEVZzE8q8-_CzR5Mw-kSphv1tx1Se15X7s'\n",
        "bot = telebot.TeleBot(API_TOKEN)\n",
        "settings = {}\n",
        "enabled = [6210177349]\n",
        "\n",
        "def isEnabled(id):\n",
        "  return id in enabled if len(enabled)>0 else True\n",
        "\n",
        "@bot.message_handler(commands=['start', 'help'])\n",
        "def send_welcome(message):\n",
        "  if isEnabled(message.chat.id):\n",
        "\t  bot.reply_to(message, \"Welcome to DeepFake AI\\n\\nDeepFake use artificial intelligence (AI) to make a video of someone by manipulating their face and body.\\n\\n\"\"Steps to produce DeepFake video:\\n1. Send spoof fake photo in square (1:1 ratio)\\n2. Send your face expression with voice recorded video.\\n3. DeepFake video is ready.\\n\\n⚠️ Strictly for paid subscribers use only.\")\n",
        "\n",
        "def get(key,id_utente,default_value=False):\n",
        "  if not id_utente in settings:\n",
        "    settings[id_utente]={}\n",
        "  if not key in settings[id_utente]:\n",
        "    settings[id_utente][key]=default_value\n",
        "  return settings[id_utente][key]\n",
        "\n",
        "def set(key,value,id_utente):\n",
        "  get(key,id_utente) #init\n",
        "  settings[id_utente][key]=value\n",
        "\n",
        "#fix for wrong length speedup on OnePlus\n",
        "def get_length(filename):\n",
        "    result = subprocess.run([\"ffprobe\", \"-v\", \"error\", \"-show_entries\",\n",
        "                             \"format=duration\", \"-of\",\n",
        "                             \"default=noprint_wrappers=1:nokey=1\", filename],\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT)\n",
        "    return float(result.stdout)\n",
        "\n",
        "@bot.message_handler(commands=['output'])\n",
        "def videomode(message):\n",
        "  if isEnabled(message.chat.id):\n",
        "    if get('mode',message.chat.id):\n",
        "      set('mode',False,message.chat.id)\n",
        "    else:\n",
        "      set('mode',True,message.chat.id)\n",
        "    bot.reply_to(message, \"I've changed mode correctly.\")\n",
        "\n",
        "@bot.message_handler(commands=['speed'])\n",
        "def speedmode(message):\n",
        "  if isEnabled(message.chat.id):\n",
        "    if get('dynamic_scale',message.chat.id):\n",
        "      set('dynamic_scale',False,message.chat.id)\n",
        "    else:\n",
        "      set('dynamic_scale',True,message.chat.id)\n",
        "    bot.reply_to(message, \"I have changed the speed adaptation correctly.\")\n",
        "\n",
        "@bot.message_handler(commands=['relative'])\n",
        "def relativemode(message):\n",
        "  if isEnabled(message.chat.id):\n",
        "    if get('relative',message.chat.id,default_value=True):\n",
        "      set('relative',False,message.chat.id)\n",
        "    else:\n",
        "      set('relative',True,message.chat.id)\n",
        "    bot.reply_to(message, f\"I have changed the relative mode to {get('relative',message.chat.id)} correctly.\")\n",
        "\n",
        "@bot.message_handler(content_types=['photo'])\n",
        "def download_pic(message):\n",
        "  if isEnabled(message.chat.id):\n",
        "    file_info = bot.get_file([ph.file_id for ph in message.photo if ph.file_size== max([photo.file_size for photo in message.photo])][0])\n",
        "    file = requests.get('https://api.telegram.org/file/bot{0}/{1}'.format(API_TOKEN, file_info.file_path))\n",
        "    id = message.chat.id;\n",
        "    open(f'../src{id}.jpg', 'wb').write(file.content)\n",
        "    bot.reply_to(message, \"Perfect, now send me a video note or a video! (For best results keep head movements to a minimum and keep a static background)\")\n",
        "\n",
        "@bot.message_handler(content_types=['video_note','video'])\n",
        "def download_video(message):\n",
        "  if isEnabled(message.chat.id):\n",
        "    try:\n",
        "      id = message.chat.id;\n",
        "      file_info = bot.get_file(message.video_note.file_id if message.content_type == 'video_note' else message.video.file_id)\n",
        "      print('https://api.telegram.org/file/bot{0}/{1}'.format(API_TOKEN, file_info.file_path));\n",
        "      file = requests.get('https://api.telegram.org/file/bot{0}/{1}'.format(API_TOKEN, file_info.file_path))\n",
        "      open(f'../target{id}.mp4', 'wb').write(file.content)\n",
        "      #extract audio\n",
        "      subprocess.call(['ffmpeg', '-i', f'../target{id}.mp4', '-vn', '-acodec','copy', f'../out{id}.aac'])\n",
        "      if os.path.exists(f'../src{id}.jpg'):\n",
        "        bot.reply_to(message, \"I am generating the deep fake...\")\n",
        "        bot.send_chat_action(id, 'record_video')\n",
        "        source_image = imageio.imread(f'../src{id}.jpg')\n",
        "        source_image = resize(source_image, (256, 256))[..., :3]\n",
        "      else:\n",
        "        bot.reply_to(message, \"You have to send me an image first!\")\n",
        "        return\n",
        "      try:\n",
        "        driving_video = imageio.mimread(f'../target{id}.mp4')\n",
        "      except Exception as e:\n",
        "        reader = imageio.get_reader(f'../target{id}.mp4')\n",
        "        driving_video = []\n",
        "        try:\n",
        "            for im in reader:\n",
        "                driving_video.append(im)\n",
        "        except RuntimeError:\n",
        "            pass\n",
        "      driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
        "      predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=get('relative',message.chat.id,default_value=True),cpu=cpu)\n",
        "      imageio.mimsave(f'../generated{id}.mp4', [img_as_ubyte(frame) for frame in predictions])\n",
        "      #normal speed\n",
        "      if get('dynamic_scale',message.chat.id):\n",
        "        dynamic_scale=1/(get_length(f'../generated{id}.mp4')/get_length(f'../target{id}.mp4'))\n",
        "      else:\n",
        "        dynamic_scale=0.33334\n",
        "\n",
        "      subprocess.call(['ffmpeg', '-itsscale',f'{dynamic_scale}', '-i', f'../generated{id}.mp4', '-c','copy', f'../generated_fast{id}.mp4'])\n",
        "      print(get_length(f'../generated_fast{id}.mp4'))\n",
        "      #add audio\n",
        "      subprocess.call(['ffmpeg', '-i', f'../generated_fast{id}.mp4', '-i',f'../out{id}.aac', '-c', 'copy','-map','0:v:0','-map','1:a:0', f'../tosend{id}.mp4'])\n",
        "      videonote = open(f'../tosend{id}.mp4', 'rb')\n",
        "      if get('mode',message.chat.id):\n",
        "        bot.send_video(id, videonote)\n",
        "      else:\n",
        "        bot.send_video_note(id,videonote)\n",
        "    finally:\n",
        "      #cleanup\n",
        "      if os.path.exists(f'../target{id}.mp4'):\n",
        "        os.remove(f'../target{id}.mp4')\n",
        "      if os.path.exists(f'../generated{id}.mp4'):\n",
        "        os.remove(f'../generated{id}.mp4')\n",
        "      if os.path.exists(f'../generated_fast{id}.mp4'):\n",
        "        os.remove(f'../generated_fast{id}.mp4')\n",
        "      if os.path.exists(f'../tosend{id}.mp4'):\n",
        "        os.remove(f'../tosend{id}.mp4')\n",
        "      if os.path.exists(f'../out{id}.aac'):\n",
        "        os.remove(f'../out{id}.aac')\n",
        "      if os.path.exists(f'../src{id}.jpg'):\n",
        "        os.remove(f'../src{id}.jpg')\n",
        "\n",
        "bot.polling()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:pass"
      ],
      "metadata": {
        "id": "JXRqfnTyupH5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}